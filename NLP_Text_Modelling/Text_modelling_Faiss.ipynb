{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiTNjjbs9vowMpvzyQeqzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f09f38de9f64b91af45cd8a883a59af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84bc3285946f4593a994c8a99980628b",
              "IPY_MODEL_b2635fb7d58641d0882508b5820b2c85",
              "IPY_MODEL_f921b23832f74f48bf1536721fa6c652"
            ],
            "layout": "IPY_MODEL_b7802174bfe943458ce4d1e54b617342"
          }
        },
        "84bc3285946f4593a994c8a99980628b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43bd3680d9284887930c237aa598d95a",
            "placeholder": "​",
            "style": "IPY_MODEL_f82c620dfebe4d5d991697cc8e913dc3",
            "value": "Batches: 100%"
          }
        },
        "b2635fb7d58641d0882508b5820b2c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0d7f65697c4cc1a5856703162d52e4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d0c6402e7a4f55b056479b034e3e9c",
            "value": 1
          }
        },
        "f921b23832f74f48bf1536721fa6c652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f6b9b179474d809061296032dd0717",
            "placeholder": "​",
            "style": "IPY_MODEL_c56cd40b6b3244369be20656d2fc5f03",
            "value": " 1/1 [00:02&lt;00:00,  2.01s/it]"
          }
        },
        "b7802174bfe943458ce4d1e54b617342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bd3680d9284887930c237aa598d95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82c620dfebe4d5d991697cc8e913dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0d7f65697c4cc1a5856703162d52e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d0c6402e7a4f55b056479b034e3e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46f6b9b179474d809061296032dd0717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56cd40b6b3244369be20656d2fc5f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanghoshsbi/.github.io/blob/master/NLP_Text_Modelling/Text_modelling_Faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nshLe_Tcmdye",
        "outputId": "8417fc39-87b8-44aa-aad4-32f84a783123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Common\n",
        "!pip install tqdm\n",
        "\n",
        "# Local embeddings + FAISS\n",
        "!pip install sentence-transformers faiss-cpu\n",
        "\n",
        "\n",
        "# (Optional) For nicer docs handling\n",
        "!pip install langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "rag_ingest.py\n",
        "\n",
        "Reads a JSON array from 'ragtext.txt' (the format provided in the conversation),\n",
        "prepares documents, and builds a vector store usable in a RAG pipeline.\n",
        "\n",
        "Supports two backends:\n",
        " - 'faiss_local' : sentence-transformers + faiss (no cloud keys)\n",
        " - 'openai_chroma': OpenAI embeddings + chroma (requires OPENAI_API_KEY in env)\n",
        "\n",
        "Usage:\n",
        "    python rag_ingest.py\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Optional: If you want to create LangChain Document objects later, import:\n",
        "# from langchain.schema import Document   # Uncomment if using langchain\n",
        "\n",
        "# -------------------------\n",
        "# Data classes / helpers\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class ChunkDoc:\n",
        "    id: str\n",
        "    theme: str\n",
        "    suggested_size: str\n",
        "    text: str\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "def load_json_chunks(path: str) -> List[ChunkDoc]:\n",
        "    \"\"\"Load the JSON array from the given file and convert to ChunkDoc list.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    docs: List[ChunkDoc] = []\n",
        "    for i, item in enumerate(data):\n",
        "        chunk_id = item.get(\"Chunk #\", f\"chunk_{i+1}\")\n",
        "        theme = item.get(\"Theme/Topic\", \"\")\n",
        "        size = item.get(\"Suggested Chunk Size (Approx.)\", \"\")\n",
        "        content = item.get(\"Chunk Content\", \"\")\n",
        "        # Build metadata; include source if you need later\n",
        "        metadata = {\n",
        "            \"theme\": theme,\n",
        "            \"suggested_size\": size,\n",
        "            \"chunk_number\": chunk_id\n",
        "        }\n",
        "        docs.append(ChunkDoc(id=str(chunk_id), theme=theme, suggested_size=size, text=content, metadata=metadata))\n",
        "    return docs\n",
        "\n",
        "# -------------------------\n",
        "# Backend A: sentence-transformers + FAISS (local)\n",
        "# -------------------------\n",
        "def build_faiss_local(docs: List[ChunkDoc], model_name: str = \"all-MiniLM-L6-v2\", save_path: str = \"faiss_index\") -> Tuple[Any, Any]:\n",
        "    \"\"\"\n",
        "    Create embeddings with sentence-transformers and index them with FAISS.\n",
        "    Returns (index, encoder_model). Saves index and doc-mapping to disk.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        import faiss\n",
        "    except ImportError:\n",
        "        raise RuntimeError(\"Install sentence-transformers and faiss-cpu (pip install sentence-transformers faiss-cpu)\")\n",
        "\n",
        "    model = SentenceTransformer(model_name)\n",
        "    texts = [d.text for d in docs]\n",
        "    print(\"Creating embeddings with\", model_name)\n",
        "    embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)  # inner product (cosine if normalized)\n",
        "    # normalize to get cosine similarity behavior\n",
        "    faiss.normalize_L2(embeddings)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    # Save index and metadata\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    faiss.write_index(index, os.path.join(save_path, \"index.faiss\"))\n",
        "\n",
        "    # Save doc metadata and texts for retrieval mapping\n",
        "    mapping = [{\"id\": d.id, \"metadata\": d.metadata, \"text\": d.text} for d in docs]\n",
        "    with open(os.path.join(save_path, \"mapping.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"FAISS index + mapping saved to {save_path}\")\n",
        "    return index, model\n",
        "\n",
        "def query_faiss(index, encoder_model, docs_path: str, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Query the FAISS index and return top_k docs with metadata and scores.\"\"\"\n",
        "    import faiss\n",
        "    # load mapping\n",
        "    mapping_file = os.path.join(docs_path, \"mapping.json\")\n",
        "    with open(mapping_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    q_emb = encoder_model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    distances, indices = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for score, idx in zip(distances[0], indices[0]):\n",
        "        if idx < 0 or idx >= len(mapping):\n",
        "            continue\n",
        "        entry = mapping[idx]\n",
        "        results.append({\"score\": float(score), \"id\": entry[\"id\"], \"metadata\": entry[\"metadata\"], \"text\": entry[\"text\"]})\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Backend B: OpenAI embeddings + Chroma\n",
        "# -------------------------\n",
        "def build_chroma_openai(docs: List[ChunkDoc], persist_dir: str = \"chroma_db\", openai_api_key: str = None, embed_model_name: str = \"text-embedding-3-small\") -> Any:\n",
        "    \"\"\"\n",
        "    Build a Chroma DB with OpenAI embeddings.\n",
        "    Requires environment variable OPENAI_API_KEY or pass key as argument.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import chromadb\n",
        "        from chromadb.utils import embedding_functions\n",
        "    except ImportError:\n",
        "        raise RuntimeError(\"Install chromadb and openai (pip install chromadb openai)\")\n",
        "\n",
        "    if openai_api_key is None:\n",
        "        openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise RuntimeError(\"OpenAI API key not found. Set OPENAI_API_KEY env var or pass it to the function.\")\n",
        "\n",
        "    client = chromadb.Client()\n",
        "    # Use the OpenAI embedding function wrapped for chroma\n",
        "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=openai_api_key, model_name=embed_model_name)\n",
        "\n",
        "    # Create or get collection\n",
        "    collection = client.create_collection(name=\"rag_chunks\", embedding_function=openai_ef)\n",
        "\n",
        "    ids = [d.id for d in docs]\n",
        "    metadatas = [d.metadata for d in docs]\n",
        "    texts = [d.text for d in docs]\n",
        "\n",
        "    # upsert data\n",
        "    collection.add(ids=ids, metadatas=metadatas, documents=texts)\n",
        "    print(f\"Chroma collection 'rag_chunks' created/populated (persist_dir not used in in-memory client).\")\n",
        "    return collection\n",
        "\n",
        "def query_chroma(collection, query: str, top_k: int = 3):\n",
        "    results = collection.query(query_texts=[query], n_results=top_k)\n",
        "    # results is a dict with 'documents', 'metadatas', 'distances', 'ids'\n",
        "    out = []\n",
        "    docs = results.get(\"documents\", [[]])[0]\n",
        "    metas = results.get(\"metadatas\", [[]])[0]\n",
        "    dists = results.get(\"distances\", [[]])[0]\n",
        "    ids = results.get(\"ids\", [[]])[0]\n",
        "    for i in range(len(docs)):\n",
        "        out.append({\"id\": ids[i], \"text\": docs[i], \"metadata\": metas[i], \"score\": dists[i]})\n",
        "    return out\n",
        "\n",
        "# -------------------------\n",
        "# Utilities\n",
        "# -------------------------\n",
        "def prepare_docs_for_rag(docs: List[ChunkDoc]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Return a simple list of dicts (id, text, metadata) ready for any RAG/vector store pipeline.\"\"\"\n",
        "    return [{\"id\": d.id, \"text\": d.text, \"metadata\": d.metadata} for d in docs]\n",
        "\n",
        "# -------------------------\n",
        "# Example run\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    RAG_FILE = \"ragtext.txt\"   # file that contains the JSON array\n",
        "    if not os.path.exists(RAG_FILE):\n",
        "        raise FileNotFoundError(f\"{RAG_FILE} not found. Put your JSON array in this file.\")\n",
        "\n",
        "    docs = load_json_chunks(RAG_FILE)\n",
        "    print(f\"Loaded {len(docs)} chunks from {RAG_FILE}\")\n",
        "\n",
        "    # Choose backend: 'faiss_local' or 'openai_chroma'\n",
        "    VSTORE_BACKEND = os.environ.get(\"VSTORE_BACKEND\", \"faiss_local\")\n",
        "\n",
        "    if VSTORE_BACKEND == \"faiss_local\":\n",
        "        index, encoder = build_faiss_local(docs, save_path=\"faiss_index\")\n",
        "        # Demonstrate a query\n",
        "        q = \"If buying lottery som bad then why people still keep doing it?\"\n",
        "        print(\"Query:\", q)\n",
        "        results = query_faiss(index, encoder, docs_path=\"faiss_index\", query=q, top_k=4)\n",
        "        for r in results:\n",
        "            print(\"SCORE:\", r[\"score\"], \"ID:\", r[\"id\"], \"THEME:\", r[\"metadata\"].get(\"theme\"))\n",
        "            print(\"->\", r[\"text\"].replace(\"\\n\", \" \"), \"...\\n\")\n",
        "            # Save full result (score, id, theme, text) into a .txt file\n",
        "            # Build the combined text for this result\n",
        "            output_text = (\n",
        "                f\"SCORE: {r['score']}\\n\"\n",
        "                f\"ID: {r['id']}\\n\"\n",
        "                f\"THEME: {r['metadata'].get('theme')}\\n\\n\"\n",
        "                f\"TEXT:\\n{r['text']}\\n\"\n",
        "                \"------------------------------------------------------------\\n\\n\"\n",
        "            )\n",
        "\n",
        "            with open(f\"retrieved_rag.txt\", \"a\", encoding=\"utf-8\") as out:\n",
        "                  out.write(output_text)\n",
        "    elif VSTORE_BACKEND == \"openai_chroma\":\n",
        "        OPENAI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "        collection = build_chroma_openai(docs, openai_api_key=OPENAI_KEY)\n",
        "        q = \"How new are index funds and 401(k)s?\"\n",
        "        print(\"Query:\", q)\n",
        "        results = query_chroma(collection, q, top_k=4)\n",
        "        for r in results:\n",
        "            print(\"ID:\", r[\"id\"], \"SCORE:\", r[\"score\"], \"THEME:\", r[\"metadata\"].get(\"theme\"))\n",
        "            print(\"->\", r[\"text\"].replace(\"\\n\", \" \"), \"...\\n\")\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown VSTORE_BACKEND: {VSTORE_BACKEND}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "5f09f38de9f64b91af45cd8a883a59af",
            "84bc3285946f4593a994c8a99980628b",
            "b2635fb7d58641d0882508b5820b2c85",
            "f921b23832f74f48bf1536721fa6c652",
            "b7802174bfe943458ce4d1e54b617342",
            "43bd3680d9284887930c237aa598d95a",
            "f82c620dfebe4d5d991697cc8e913dc3",
            "5b0d7f65697c4cc1a5856703162d52e4",
            "68d0c6402e7a4f55b056479b034e3e9c",
            "46f6b9b179474d809061296032dd0717",
            "c56cd40b6b3244369be20656d2fc5f03"
          ]
        },
        "id": "VbVXAArdmxiw",
        "outputId": "8994fd4e-a1f2-4787-ee20-eb020fb6db52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10 chunks from ragtext.txt\n",
            "Creating embeddings with all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f09f38de9f64b91af45cd8a883a59af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index + mapping saved to faiss_index\n",
            "Query: If buying lottery som bad then why people still keep doing it?\n",
            "SCORE: 0.5065473318099976 ID: 8 THEME: Lottery Tickets & Paying for a Dream\n",
            "-> Every decision people make with money is justified by taking the information they have at the moment and plugging it into their unique mental model of how the world works. Those people can be misinformed. They can have incomplete information. They can be bad at math. They can be persuaded by rotten marketing. They can have no idea what they’re doing. They can misjudge the consequences of their actions. Oh, can they ever. But every financial decision a person makes, makes sense to them in that moment and checks the boxes they need to check. They tell themselves a story about what they’re doing and why they’re doing it, and that story has been shaped by their own unique experiences. Take a simple example: lottery tickets. Americans spend more on them than movies, video games, music, sporting events, and books combined. And who buys them? Mostly poor people. The lowest-income households in the U.S. on average spend $412 a year on lotto tickets, four times the amount of those in the highest income groups. Forty percent of Americans cannot come up with $400 in an emergency. Which is to say: Those buying $400 in lottery tickets are by and large the same people who say they couldn’t come up with $400 in an emergency. They are blowing their safety nets on something with a one-in-millions chance of hitting it big. That seems crazy to me. It probably seems crazy to you, too. But I’m not in the lowest income group. You’re likely not, either. So it’s hard for many of us to intuitively grasp the subconscious reasoning of low-income lottery ticket buyers. But strain a little, and you can imagine it going something like this: We live paycheck-to-paycheck and saving seems out of reach. Our prospects for much higher wages seem out of reach. We can’t afford nice vacations, new cars, health insurance, or homes in safe neighborhoods. We can’t put our kids through college without crippling debt. Much of the stuff you people who read finance books either have now, or have a good chance of getting, we don’t. Buying a lottery ticket is the only time in our lives we can hold a tangible dream of getting the good stuff that you already have and take for granted. We are paying for a dream, and you may not understand that because you are already living a dream. That’s why we buy more tickets than you do. You don’t have to agree with this reasoning. Buying lotto tickets when you’re broke is still a bad idea. But I can kind of understand why lotto ticket sales persist. And that idea—“What you’re doing seems crazy but I kind of understand why you’re doing it.”—uncovers the root of many of our financial decisions. ...\n",
            "\n",
            "SCORE: 0.39678215980529785 ID: 4 THEME: Academic Evidence: Malmendier & Nagel Study\n",
            "-> We all think we know how the world works. But we’ve all only experienced a tiny sliver of it. As investor Michael Batnick says, “some lessons have to be experienced before they can be understood.” We are all victims, in different ways, to that truth. In 2006 economists Ulrike Malmendier and Stefan Nagel from the National Bureau of Economic Research dug through 50 years of the Survey of Consumer Finances—a detailed look at what Americans do with their money. In theory people should make investment decisions based on their goals and the characteristics of the investment options available to them at the time. But that’s not what people do. The economists found that people’s lifetime investment decisions are heavily anchored to the experiences those investors had in their own generation—especially experiences early in their adult life. If you grew up when inflation was high, you invested less of your money in bonds later in life compared to those who grew up when inflation was low. If you happened to grow up when the stock market was strong, you invested more of your money in stocks later in life compared to those who grew up when stocks were weak. The economists wrote: “Our findings suggest that individual investors’ willingness to bear risk depends on personal history.” ...\n",
            "\n",
            "SCORE: 0.3672236204147339 ID: 1 THEME: Introduction: The Anchor of Personal Experience\n",
            "-> Let me tell you about a problem. It might make you feel better about what you do with your money, and less judgmental about what other people do with theirs. People do some crazy things with money. But no one is crazy. Here’s the thing: People from different generations, raised by different parents who earned different incomes and held different values, in different parts of the world, born into different economies, experiencing different job markets with different incentives and different degrees of luck, learn very different lessons. Everyone has their own unique experience with how the world works. And what you’ve experienced is more compelling than what you learn second-hand. So all of us—you, me, everyone—go through life anchored to a set of views about how money works that vary wildly from person to person. What seems crazy to you might make sense to me. ...\n",
            "\n",
            "SCORE: 0.3621059060096741 ID: 9 THEME: The Newness of Modern Finance (Retirement, 401k, Roth IRA)\n",
            "-> Few people make financial decisions purely with a spreadsheet. They make them at the dinner table, or in a company meeting. Places where personal history, your own unique view of the world, ego, pride, marketing, and odd incentives are scrambled together into a narrative that works for you. Another important point that helps explain why money decisions are so difficult, and why there is so much misbehavior, is to recognize how new this topic is. Money has been around a long time. King Alyattes of Lydia, now part of Turkey, is thought to have created the first official currency in 600 BC. But the modern foundation of money decisions—saving and investing—is based around concepts that are practically infants. Take retirement. At the end of 2018 there was $27 trillion in U.S. retirement accounts, making it the main driver of the common investor’s saving and investing decisions. But the entire concept of being entitled to retirement is, at most, two generations old. Before World War II most Americans worked until they died. That was the expectation and the reality. The labor force participation rate of men age 65 and over was above 50% until the 1940s. Social Security aimed to change this. But its initial benefits were nothing close to a proper pension. When Ida May Fuller cashed the first Social Security check in 1940, it was for $22.54, or $416 adjusted for inflation. It was not until the 1980s that the average Social Security check for retirees exceeded $1,000 a month adjusted for inflation. More than a quarter of Americans over age 65 were classified by the Census Bureau as living in poverty until the late 1960s. There is a widespread belief along the lines of, “everyone used to have a private pension.” But this is wildly exaggerated. The Employee Benefit Research Institute explains: “Only a quarter of those age 65 or older had pension income in 1975.” Among that lucky minority, only 15% of household income came from a pension. The New York Times wrote in 1955 about the growing desire, but continued inability, to retire: “To rephrase an old saying: everyone talks about retirement, but apparently very few do anything about it.” It was not until the 1980s that the idea that everyone deserves, and should have, a dignified retirement took hold. And the way to get that dignified retirement ever since has been an expectation that everyone will save and invest their own money. Let me reiterate how new this idea is: The 401(k)—the backbone savings vehicle of American retirement—did not exist until 1978. The Roth IRA was not born until 1998. If it were a person it would be barely old enough to drink. It should surprise no one that many of us are bad at saving and investing for retirement. We’re not crazy. We’re all just newbies. ...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}