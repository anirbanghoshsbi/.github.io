{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHmKxLE2mmxdDC4c5Jx2lo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf26332bc1114643888132449b589e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86a119edbffb49e18d0d8cae53534b50",
              "IPY_MODEL_dd43450743f54f8e993d2ed054e2cb18",
              "IPY_MODEL_a87f3be4dbff49e9a42964ca183b49ae"
            ],
            "layout": "IPY_MODEL_58e275eb742e4ceda3ae5c86c7f92d01"
          }
        },
        "86a119edbffb49e18d0d8cae53534b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8a56b95d8d4ca99d2952c8104f4e50",
            "placeholder": "​",
            "style": "IPY_MODEL_91fffa6a926b41b89a08480231582a02",
            "value": "Batches: 100%"
          }
        },
        "dd43450743f54f8e993d2ed054e2cb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16669cc4a42346aaa1cd451d22e9ce7e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1173019758884e6bb971f7ebf651734e",
            "value": 1
          }
        },
        "a87f3be4dbff49e9a42964ca183b49ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c75d2c8bdd4b558ad4930b6ee64aa3",
            "placeholder": "​",
            "style": "IPY_MODEL_6f008e76fe9e484395f60c4800f3c770",
            "value": " 1/1 [00:02&lt;00:00,  2.26s/it]"
          }
        },
        "58e275eb742e4ceda3ae5c86c7f92d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8a56b95d8d4ca99d2952c8104f4e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91fffa6a926b41b89a08480231582a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16669cc4a42346aaa1cd451d22e9ce7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1173019758884e6bb971f7ebf651734e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06c75d2c8bdd4b558ad4930b6ee64aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f008e76fe9e484395f60c4800f3c770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanghoshsbi/.github.io/blob/master/NLP_Text_Modelling/Text_modelling_Faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nshLe_Tcmdye",
        "outputId": "3a268930-6454-4fbb-f08b-8899b5b62f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Common\n",
        "!pip install tqdm --q\n",
        "\n",
        "# Local embeddings + FAISS\n",
        "!pip install sentence-transformers faiss-cpu --q\n",
        "\n",
        "\n",
        "# (Optional) For nicer docs handling\n",
        "!pip install langchain  --q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "rag_ingest.py\n",
        "\n",
        "Reads a JSON array from 'ragtext.txt' (the format provided in the conversation),\n",
        "prepares documents, and builds a vector store usable in a RAG pipeline.\n",
        "\n",
        "Supports two backends:\n",
        " - 'faiss_local' : sentence-transformers + faiss (no cloud keys)\n",
        " - 'openai_chroma': OpenAI embeddings + chroma (requires OPENAI_API_KEY in env)\n",
        "\n",
        "Usage:\n",
        "    python rag_ingest.py\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Optional: If you want to create LangChain Document objects later, import:\n",
        "# from langchain.schema import Document   # Uncomment if using langchain\n",
        "\n",
        "# -------------------------\n",
        "# Data classes / helpers\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class ChunkDoc:\n",
        "    id: str\n",
        "    theme: str\n",
        "    suggested_size: str\n",
        "    text: str\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "def load_json_chunks(path: str) -> List[ChunkDoc]:\n",
        "    \"\"\"Load the JSON array from the given file and convert to ChunkDoc list.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    docs: List[ChunkDoc] = []\n",
        "    for i, item in enumerate(data):\n",
        "        chunk_id = item.get(\"Chunk #\", f\"chunk_{i+1}\")\n",
        "        theme = item.get(\"Theme/Topic\", \"\")\n",
        "        size = item.get(\"Suggested Chunk Size (Approx.)\", \"\")\n",
        "        content = item.get(\"Chunk Content\", \"\")\n",
        "        # Build metadata; include source if you need later\n",
        "        metadata = {\n",
        "            \"theme\": theme,\n",
        "            \"suggested_size\": size,\n",
        "            \"chunk_number\": chunk_id\n",
        "        }\n",
        "        docs.append(ChunkDoc(id=str(chunk_id), theme=theme, suggested_size=size, text=content, metadata=metadata))\n",
        "    return docs\n",
        "\n",
        "# -------------------------\n",
        "# Backend A: sentence-transformers + FAISS (local)\n",
        "# -------------------------\n",
        "def build_faiss_local(docs: List[ChunkDoc], model_name: str = \"all-MiniLM-L6-v2\", save_path: str = \"faiss_index\") -> Tuple[Any, Any]:\n",
        "    \"\"\"\n",
        "    Create embeddings with sentence-transformers and index them with FAISS.\n",
        "    Returns (index, encoder_model). Saves index and doc-mapping to disk.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        import faiss\n",
        "    except ImportError:\n",
        "        raise RuntimeError(\"Install sentence-transformers and faiss-cpu (pip install sentence-transformers faiss-cpu)\")\n",
        "\n",
        "    model = SentenceTransformer(model_name)\n",
        "    texts = [d.text for d in docs]\n",
        "    print(\"Creating embeddings with\", model_name)\n",
        "    embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)  # inner product (cosine if normalized)\n",
        "    # normalize to get cosine similarity behavior\n",
        "    faiss.normalize_L2(embeddings)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    # Save index and metadata\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    faiss.write_index(index, os.path.join(save_path, \"index.faiss\"))\n",
        "\n",
        "    # Save doc metadata and texts for retrieval mapping\n",
        "    mapping = [{\"id\": d.id, \"metadata\": d.metadata, \"text\": d.text} for d in docs]\n",
        "    with open(os.path.join(save_path, \"mapping.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"FAISS index + mapping saved to {save_path}\")\n",
        "    return index, model\n",
        "\n",
        "def query_faiss(index, encoder_model, docs_path: str, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Query the FAISS index and return top_k docs with metadata and scores.\"\"\"\n",
        "    import faiss\n",
        "    # load mapping\n",
        "    mapping_file = os.path.join(docs_path, \"mapping.json\")\n",
        "    with open(mapping_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    q_emb = encoder_model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    distances, indices = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for score, idx in zip(distances[0], indices[0]):\n",
        "        if idx < 0 or idx >= len(mapping):\n",
        "            continue\n",
        "        entry = mapping[idx]\n",
        "        results.append({\"score\": float(score), \"id\": entry[\"id\"], \"metadata\": entry[\"metadata\"], \"text\": entry[\"text\"]})\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Backend B: OpenAI embeddings + Chroma\n",
        "# -------------------------\n",
        "def build_chroma_openai(docs: List[ChunkDoc], persist_dir: str = \"chroma_db\", openai_api_key: str = None, embed_model_name: str = \"text-embedding-3-small\") -> Any:\n",
        "    \"\"\"\n",
        "    Build a Chroma DB with OpenAI embeddings.\n",
        "    Requires environment variable OPENAI_API_KEY or pass key as argument.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import chromadb\n",
        "        from chromadb.utils import embedding_functions\n",
        "    except ImportError:\n",
        "        raise RuntimeError(\"Install chromadb and openai (pip install chromadb openai)\")\n",
        "\n",
        "    if openai_api_key is None:\n",
        "        openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise RuntimeError(\"OpenAI API key not found. Set OPENAI_API_KEY env var or pass it to the function.\")\n",
        "\n",
        "    client = chromadb.Client()\n",
        "    # Use the OpenAI embedding function wrapped for chroma\n",
        "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=openai_api_key, model_name=embed_model_name)\n",
        "\n",
        "    # Create or get collection\n",
        "    collection = client.create_collection(name=\"rag_chunks\", embedding_function=openai_ef)\n",
        "\n",
        "    ids = [d.id for d in docs]\n",
        "    metadatas = [d.metadata for d in docs]\n",
        "    texts = [d.text for d in docs]\n",
        "\n",
        "    # upsert data\n",
        "    collection.add(ids=ids, metadatas=metadatas, documents=texts)\n",
        "    print(f\"Chroma collection 'rag_chunks' created/populated (persist_dir not used in in-memory client).\")\n",
        "    return collection\n",
        "\n",
        "def query_chroma(collection, query: str, top_k: int = 3):\n",
        "    results = collection.query(query_texts=[query], n_results=top_k)\n",
        "    # results is a dict with 'documents', 'metadatas', 'distances', 'ids'\n",
        "    out = []\n",
        "    docs = results.get(\"documents\", [[]])[0]\n",
        "    metas = results.get(\"metadatas\", [[]])[0]\n",
        "    dists = results.get(\"distances\", [[]])[0]\n",
        "    ids = results.get(\"ids\", [[]])[0]\n",
        "    for i in range(len(docs)):\n",
        "        out.append({\"id\": ids[i], \"text\": docs[i], \"metadata\": metas[i], \"score\": dists[i]})\n",
        "    return out\n",
        "\n",
        "# -------------------------\n",
        "# Utilities\n",
        "# -------------------------\n",
        "def prepare_docs_for_rag(docs: List[ChunkDoc]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Return a simple list of dicts (id, text, metadata) ready for any RAG/vector store pipeline.\"\"\"\n",
        "    return [{\"id\": d.id, \"text\": d.text, \"metadata\": d.metadata} for d in docs]\n",
        "\n",
        "# -------------------------\n",
        "# Example run\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    RAG_FILE = \"ragtext.txt\"   # file that contains the JSON array\n",
        "    if not os.path.exists(RAG_FILE):\n",
        "        raise FileNotFoundError(f\"{RAG_FILE} not found. Put your JSON array in this file.\")\n",
        "\n",
        "    docs = load_json_chunks(RAG_FILE)\n",
        "    print(f\"Loaded {len(docs)} chunks from {RAG_FILE}\")\n",
        "\n",
        "    # Choose backend: 'faiss_local' or 'openai_chroma'\n",
        "    VSTORE_BACKEND = os.environ.get(\"VSTORE_BACKEND\", \"faiss_local\")\n",
        "\n",
        "    if VSTORE_BACKEND == \"faiss_local\":\n",
        "        index, encoder = build_faiss_local(docs, save_path=\"faiss_index\")\n",
        "        # Demonstrate a query\n",
        "        q = \"Why no one is crazy in this world?\"\n",
        "        print(\"Query:\", q)\n",
        "        results = query_faiss(index, encoder, docs_path=\"faiss_index\", query=q, top_k=4)\n",
        "        for r in results:\n",
        "            print(\"SCORE:\", r[\"score\"], \"ID:\", r[\"id\"], \"THEME:\", r[\"metadata\"].get(\"theme\"))\n",
        "            print(\"->\", r[\"text\"].replace(\"\\n\", \" \"), \"...\\n\")\n",
        "            # Save full result (score, id, theme, text) into a .txt file\n",
        "            # Build the combined text for this result\n",
        "            output_text = (\n",
        "                f\"SCORE: {r['score']}\\n\"\n",
        "                f\"ID: {r['id']}\\n\"\n",
        "                f\"THEME: {r['metadata'].get('theme')}\\n\\n\"\n",
        "                f\"TEXT:\\n{r['text']}\\n\"\n",
        "                \"------------------------------------------------------------\\n\\n\"\n",
        "            )\n",
        "\n",
        "            with open(f\"retrieved_rag.txt\", \"a\", encoding=\"utf-8\") as out:\n",
        "                  out.write(output_text)\n",
        "    elif VSTORE_BACKEND == \"openai_chroma\":\n",
        "        OPENAI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "        collection = build_chroma_openai(docs, openai_api_key=OPENAI_KEY)\n",
        "        q = \"How new are index funds and 401(k)s?\"\n",
        "        print(\"Query:\", q)\n",
        "        results = query_chroma(collection, q, top_k=4)\n",
        "        for r in results:\n",
        "            print(\"ID:\", r[\"id\"], \"SCORE:\", r[\"score\"], \"THEME:\", r[\"metadata\"].get(\"theme\"))\n",
        "            print(\"->\", r[\"text\"].replace(\"\\n\", \" \"), \"...\\n\")\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown VSTORE_BACKEND: {VSTORE_BACKEND}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "bf26332bc1114643888132449b589e66",
            "86a119edbffb49e18d0d8cae53534b50",
            "dd43450743f54f8e993d2ed054e2cb18",
            "a87f3be4dbff49e9a42964ca183b49ae",
            "58e275eb742e4ceda3ae5c86c7f92d01",
            "cf8a56b95d8d4ca99d2952c8104f4e50",
            "91fffa6a926b41b89a08480231582a02",
            "16669cc4a42346aaa1cd451d22e9ce7e",
            "1173019758884e6bb971f7ebf651734e",
            "06c75d2c8bdd4b558ad4930b6ee64aa3",
            "6f008e76fe9e484395f60c4800f3c770"
          ]
        },
        "id": "VbVXAArdmxiw",
        "outputId": "7607ccb0-e013-4fe4-907d-1be26e2fd6d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 18 chunks from ragtext.txt\n",
            "Creating embeddings with all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf26332bc1114643888132449b589e66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index + mapping saved to faiss_index\n",
            "Query: Why no one is crazy in this world?\n",
            "SCORE: 0.42439204454421997 ID: 1 THEME: Introduction: The Anchor of Personal Experience\n",
            "-> Let me tell you about a problem. It might make you feel better about what you do with your money, and less judgmental about what other people do with theirs. People do some crazy things with money. But no one is crazy. Here’s the thing: People from different generations, raised by different parents who earned different incomes and held different values, in different parts of the world, born into different economies, experiencing different job markets with different incentives and different degrees of luck, learn very different lessons. Everyone has their own unique experience with how the world works. And what you’ve experienced is more compelling than what you learn second-hand. So all of us—you, me, everyone—go through life anchored to a set of views about how money works that vary wildly from person to person. What seems crazy to you might make sense to me. ...\n",
            "\n",
            "SCORE: 0.24394726753234863 ID: 8 THEME: Lottery Tickets & Paying for a Dream\n",
            "-> Every decision people make with money is justified by taking the information they have at the moment and plugging it into their unique mental model of how the world works. Those people can be misinformed. They can have incomplete information. They can be bad at math. They can be persuaded by rotten marketing. They can have no idea what they’re doing. They can misjudge the consequences of their actions. Oh, can they ever. But every financial decision a person makes, makes sense to them in that moment and checks the boxes they need to check. They tell themselves a story about what they’re doing and why they’re doing it, and that story has been shaped by their own unique experiences. Take a simple example: lottery tickets. Americans spend more on them than movies, video games, music, sporting events, and books combined. And who buys them? Mostly poor people. The lowest-income households in the U.S. on average spend $412 a year on lotto tickets, four times the amount of those in the highest income groups. Forty percent of Americans cannot come up with $400 in an emergency. Which is to say: Those buying $400 in lottery tickets are by and large the same people who say they couldn’t come up with $400 in an emergency. They are blowing their safety nets on something with a one-in-millions chance of hitting it big. That seems crazy to me. It probably seems crazy to you, too. But I’m not in the lowest income group. You’re likely not, either. So it’s hard for many of us to intuitively grasp the subconscious reasoning of low-income lottery ticket buyers. But strain a little, and you can imagine it going something like this: We live paycheck-to-paycheck and saving seems out of reach. Our prospects for much higher wages seem out of reach. We can’t afford nice vacations, new cars, health insurance, or homes in safe neighborhoods. We can’t put our kids through college without crippling debt. Much of the stuff you people who read finance books either have now, or have a good chance of getting, we don’t. Buying a lottery ticket is the only time in our lives we can hold a tangible dream of getting the good stuff that you already have and take for granted. We are paying for a dream, and you may not understand that because you are already living a dream. That’s why we buy more tickets than you do. You don’t have to agree with this reasoning. Buying lotto tickets when you’re broke is still a bad idea. But I can kind of understand why lotto ticket sales persist. And that idea—“What you’re doing seems crazy but I kind of understand why you’re doing it.”—uncovers the root of many of our financial decisions. ...\n",
            "\n",
            "SCORE: 0.17628774046897888 ID: 2 THEME: Specific Examples of Different Experiences\n",
            "-> The person who grew up in poverty thinks about risk and reward in ways the child of a wealthy banker cannot fathom if he tried. The person who grew up when inflation was high experienced something the person who grew up with stable prices never had to. The stock broker who lost everything during the Great Depression experienced something the tech worker basking in the glory of the late 1990s can’t imagine. The Australian who hasn’t seen a recession in 30 years has experienced something no American ever has. On and on. The list of experiences is endless. You know stuff about money that I don’t, and vice versa. You go through life with different beliefs, goals, and forecasts, than I do. That’s not because one of us is smarter than the other, or has better information. It’s because we’ve had different lives shaped by different and equally persuasive experiences. ...\n",
            "\n",
            "SCORE: 0.16204209625720978 ID: 10 THEME: The Newness of Modern Finance (College, Index Funds, Debt)\n",
            "-> Same goes for college. The share of Americans over age 25 with a bachelor’s degree has gone from less than 1 in 20 in 1940 to 1 in 4 by 2015. The average college tuition over that time rose more than fourfold adjusted for inflation. Something so big and so important hitting society so fast explains why, for example, so many people have made poor decisions with student loans over the last 20 years. There is not decades of accumulated experience to even attempt to learn from. We’re winging it. Same for index funds, which are less than 50 years old. And hedge funds, which didn’t take off until the last 25 years. Even widespread use of consumer debt—mortgages, credit cards, and car loans—did not take off until after World War II, when the GI Bill made it easier for millions of Americans to borrow. Dogs were domesticated 10,000 years ago and still retain some behaviors of their wild ancestors. Yet here we are, with between 20 and 50 years of experience in the modern financial system, hoping to be perfectly acclimated. For a topic that is so influenced by emotion versus fact, this is a problem. And it helps explain why we don’t always do what we’re supposed to with money. We all do crazy stuff with money, because we’re all relatively new to this game and what looks crazy to you might make sense to me. But no one is crazy—we all make decisions based on our own unique experiences that seem to make sense to us in a given moment. ...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}