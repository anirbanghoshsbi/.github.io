{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKYhdUjb2bcH5NRAc8Herh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanghoshsbi/.github.io/blob/master/work/portfolio/temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4cDweLADhGY",
        "outputId": "04837c92-9138-40dc-ae30-c998afb03912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  96 of 96 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering, AffinityPropagation, KMeans\n",
        "import yfinance as yf\n",
        "start_date = \"2023-10-01\"\n",
        "end_date = \"2023-12-31\"\n",
        "def get_nifty50_tickers():\n",
        "    #data = pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/STOCKS100.txt', sep='\\t')\n",
        "    data=pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/ind_nifty100list.csv')\n",
        "    nifty100 = data['Symbol'].apply(lambda x: x + \".NS\").tolist()\n",
        "    reject_lst=['MOTHERSUMI.NS', 'CADILAHC.NS', 'ADANITRANS.NS', 'SRTRANSFIN.NS', 'INFRATEL-EQ.NS','HDFC.NS','LTI.NS']\n",
        "    nifty_final= [item for item in nifty100 if item not in reject_lst]\n",
        "    return nifty_final\n",
        "def perform_clustering(stock_returns, method):\n",
        "    if method == \"agglomerative\":\n",
        "        # Agglomerative clustering with pre-determined number of clusters\n",
        "        clustering = AgglomerativeClustering(n_clusters=15, metric='euclidean', linkage='ward')\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"affinity_propagation\":\n",
        "        # Affinity propagation clustering\n",
        "        clustering = AffinityPropagation()\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"kmeans\":\n",
        "        # KMeans clustering (benchmark)\n",
        "        kmeans = KMeans(n_clusters=10)\n",
        "        clusters = kmeans.fit_predict(stock_returns)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid clustering method specified.\")\n",
        "    return clusters\n",
        "\n",
        "def construct_portfolio(clusters, embedding_data):\n",
        "    # Logic to select stocks based on clusters and distance in embedded space\n",
        "    portfolio = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        if len(cluster_indices) >= 10:\n",
        "            # Select top ten stocks with minimum Euclidean distance to cluster centers\n",
        "            distances = np.linalg.norm(embedding_data[cluster_indices] - np.mean(embedding_data[cluster_indices], axis=0), axis=1)\n",
        "            top_ten_indices = cluster_indices[np.argsort(distances)[:10]]\n",
        "            portfolio.extend(top_ten_indices)\n",
        "    return portfolio\n",
        "\n",
        "# ----- Main Loop -----\n",
        "stock_symbols=get_nifty50_tickers()\n",
        "data = yf.download(stock_symbols, start=start_date, end=end_date)[\"Adj Close\"]\n",
        "returns = data.pct_change().fillna(0)\n",
        "\n",
        "# Placeholder for handling quarterly updates\n",
        "for quarter in range(1, 5):\n",
        "    # Subset data by quarter (assuming quarterly data)\n",
        "    # ... Inside your main loop\n",
        "    for quarter in range(1, 5):\n",
        "      start_date = pd.to_datetime(f\"2023-Q{quarter}\")  # Dynamically define quarter start\n",
        "      end_date = start_date + pd.offsets.QuarterEnd()\n",
        "    print(start_date)\n",
        "    print(end_date)\n",
        "    quaterly_data = returns.loc[start_date:end_date]\n",
        "\n",
        "    # ... Now perform dimensionality reduction, clustering,\n",
        "    # and portfolio generation on 'quarterly_data'\n",
        "\n",
        "    # embedded_data = perform_dimensionality_reduction(data)\n",
        "    n_components = 2  # Reduce to 2 dimensions in this example\n",
        "    pca = PCA(n_components=n_components)\n",
        "    embedding_data = pca.fit_transform(quaterly_data)  # Obtain embeddings\n",
        "\n",
        "    # correlation_network = calculate_graphical_lasso(data)\n",
        "\n",
        "    clusters = perform_clustering(quaterly_data, method=\"agglomerative\")  # Or your chosen method\n",
        "    portfolio = construct_portfolio(clusters, embedding_data)\n",
        "\n",
        "    # Evaluate portfolio performance\n",
        "    # performance_metrics = evaluate_portfolio_performance(portfolio)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(portfolio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unTm5-sjFuUI",
        "outputId": "84ac42c2-0f68-4cd4-b636-48e37163b78f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em7DzMTJFvPq",
        "outputId": "429b3ccb-1508-4e95-d092-46497348380b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[57, 29, 3, 55, 38, 17, 39, 30, 21, 5, 52, 0, 12, 8, 26, 32, 33, 34, 36, 15]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering, AffinityPropagation, KMeans\n",
        "import yfinance as yf\n",
        "\n",
        "start_date = \"2023-10-01\"\n",
        "end_date = \"2023-12-31\"\n",
        "\n",
        "def get_nifty50_tickers():\n",
        "    data = pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/ind_nifty100list.csv')\n",
        "    nifty100 = data['Symbol'].apply(lambda x: x + \".NS\").tolist()\n",
        "    reject_lst = ['MOTHERSUMI.NS', 'CADILAHC.NS', 'ADANITRANS.NS', 'SRTRANSFIN.NS',\n",
        "                    'INFRATEL-EQ.NS', 'HDFC.NS', 'LTI.NS']\n",
        "    return [item for item in nifty100 if item not in reject_lst]\n",
        "\n",
        "def perform_clustering(stock_returns, method):\n",
        "    if method == \"agglomerative\":\n",
        "        # Agglomerative with pre-determined clusters (Euclidean metric has no effect with Ward)\n",
        "        clustering = AgglomerativeClustering(n_clusters=15, linkage='ward')\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"affinity_propagation\":\n",
        "        clustering = AffinityPropagation()\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"kmeans\":\n",
        "        kmeans = KMeans(n_clusters=10)\n",
        "        clusters = kmeans.fit_predict(stock_returns)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid clustering method specified.\")\n",
        "    return clusters\n",
        "\n",
        "def construct_portfolio(clusters, embedding_data):\n",
        "    portfolio = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        if len(cluster_indices) >= 10:\n",
        "            distances = np.linalg.norm(embedding_data[cluster_indices] - np.mean(embedding_data[cluster_indices], axis=0), axis=1)\n",
        "            top_ten_indices = cluster_indices[np.argsort(distances)[:10]]\n",
        "            portfolio.extend(top_ten_indices)\n",
        "    return portfolio\n",
        "\n",
        "# ----- Main Loop -----\n",
        "stock_symbols = get_nifty50_tickers()\n",
        "\n",
        "# Data download with basic error handling\n",
        "try:\n",
        "    data = yf.download(stock_symbols, start=start_date, end=end_date)[\"Adj Close\"]\n",
        "    returns = data.pct_change().fillna(0)\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading data: {e}\")\n",
        "    exit()  # Or handle it differently\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-J6_-MOJRPJ",
        "outputId": "c3526cc4-8333-46d7-b39e-06fec3bb3fc5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  96 of 96 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quarter handling (assumes focusing on 2023)\n",
        "for quarter in range(1, 5):\n",
        "    for quarter in range(1, 5):\n",
        "      start_date = pd.to_datetime(f\"2023-Q{quarter}\")  # Dynamically define quarter start\n",
        "      end_date = start_date + pd.offsets.QuarterEnd()\n",
        "\n",
        "\n",
        "    quarterly_data = returns.loc[start_date:end_date]\n",
        "    print(len(quarterly_data))\n",
        "    # Dimensionality Reduction\n",
        "    n_components = 2\n",
        "    pca = PCA(n_components=n_components)\n",
        "    embedding_data = pca.fit_transform(quarterly_data)\n",
        "\n",
        "    # Clustering\n",
        "    clusters = perform_clustering(quarterly_data, method=\"agglomerative\")\n",
        "    print('Deleted Previous Portfolio')\n",
        "    # Portfolio construction\n",
        "    portfolio = construct_portfolio(clusters, embedding_data)\n",
        "    print('Created Portfolio')\n",
        "\n",
        "    # Placeholder: Portfolio evaluation would go here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEjk3El5KV8y",
        "outputId": "e235adf5-0445-4b77-f4c1-b4de700b33b3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[quarterly_data[i] for i in portfolio]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "D3NGFx-SG2q5",
        "outputId": "5173c4a4-40c8-45dd-a442-f791d5734b66"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "57",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 57",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-04f76b3b3312>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mquarterly_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mportfolio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-04f76b3b3312>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mquarterly_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mportfolio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 57"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(portfolio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-jDD4ELQGTR",
        "outputId": "1458a48f-f86b-4e51-d686-ec97ac856f41"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_portfolio_performance(portfolio, quarterly_data):\n",
        "    \"\"\"Calculates performance metrics for a portfolio against a benchmark.\n",
        "\n",
        "    Args:\n",
        "        portfolio (list): List of stock indices in the portfolio.\n",
        "        quarterly_data (pandas.DataFrame): Dataframe of stock returns for the quarter.\n",
        "        benchmark_data (pandas.Series): Returns of a benchmark index for the quarter.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of performance metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    portfolio_returns = quarterly_data.iloc[portfolio].mean(axis=1)  # Average across portfolio\n",
        "    #benchmark_returns = benchmark_data\n",
        "\n",
        "    performance_metrics = {}\n",
        "\n",
        "    # --- Example Metrics ---\n",
        "    # 1. Absolute Return\n",
        "    performance_metrics[\"portfolio_return\"] = portfolio_returns.sum() * 100\n",
        "    #performance_metrics[\"benchmark_return\"] = benchmark_returns.sum() * 100\n",
        "\n",
        "    # 2. Volatility (Standard Deviation)\n",
        "    performance_metrics[\"portfolio_std\"] = portfolio_returns.std() * np.sqrt(252) * 100  # Annualized\n",
        "    #performance_metrics[\"benchmark_std\"] = benchmark_returns.std() * np.sqrt(252) * 100\n",
        "\n",
        "    # 3. Sharpe Ratio\n",
        "    rf_rate = 0.05  # Placeholder: Assume a risk-free rate\n",
        "    performance_metrics[\"sharpe_ratio\"] = (portfolio_returns.mean() - rf_rate) / portfolio_returns.std()\n",
        "\n",
        "    # ... Calculate other metrics as needed ...\n",
        "\n",
        "    return performance_metrics\n"
      ],
      "metadata": {
        "id": "8liyWXK_KXKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quarterly_data.T.iloc[portfolio]"
      ],
      "metadata": {
        "id": "HZa75S79Q9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_portfolio_performance(portfolio, quarterly_data)"
      ],
      "metadata": {
        "id": "PkLzBDb_MEc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.covariance import GraphicalLassoCV\n",
        "\n",
        "# Replace this single-value calculation ...\n",
        "# stock_returns = quarterly_data.iloc[portfolio].mean(axis=1)\n",
        "\n",
        "# ...with these lines  to keep the selected stock data\n",
        "stock_returns = quarterly_data.iloc[portfolio]  # No mean calculation here\n",
        "\n",
        "# Graphical LASSO works with covariance, not direct returns\n",
        "stock_covariance = np.cov(stock_returns.T)\n",
        "\n",
        "# Model with cross-validation to Â tune regularization\n",
        "model = GraphicalLassoCV()\n",
        "model.fit(stock_covariance)\n",
        "\n",
        "\n",
        "# Estimated precision matrix\n",
        "precision_matrix = model.precision_\n",
        "\n",
        "# Convert this to a correlation matrix (often easier to interpret)\n",
        "correlation_matrix = np.linalg.inv(precision_matrix)\n"
      ],
      "metadata": {
        "id": "JidfGHYcMHnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stock_returns"
      ],
      "metadata": {
        "id": "p5N5qiEAPpuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "# ... (Your previous code)\n",
        "\n",
        "# Create a NetworkX graph object\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes (stocks)\n",
        "G.add_nodes_from(stock_returns.columns)\n",
        "\n",
        "# Add edges based on correlation strength\n",
        "threshold = 0.05  # Set a threshold to focus on stronger correlations\n",
        "for i, stock1 in enumerate(stock_returns.columns):\n",
        "    for j, stock2 in enumerate(stock_returns.columns[i+1:]):\n",
        "        correlation = correlation_matrix[i, i+j+1]  # Account for symmetric matrix\n",
        "        if abs(correlation) > threshold:\n",
        "            G.add_edge(stock1, stock2, weight=correlation)\n",
        "\n",
        "# Customize visualization (optional)\n",
        "edge_colors = [edge[2]['weight'] for edge in G.edges(data=True)]  # Color based on weight\n",
        "pos = nx.spring_layout(G)  # Choose a layout algorithm\n",
        "\n",
        "# Draw the graph\n",
        "nx.draw(G, pos, with_labels=True, font_size=8, node_size=500, edge_color=edge_colors, edge_cmap=plt.cm.coolwarm)\n",
        "plt.title(\"Correlation Network (Graphical LASSO)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fAqM2hwSN5Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3PpyQL6N5_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}