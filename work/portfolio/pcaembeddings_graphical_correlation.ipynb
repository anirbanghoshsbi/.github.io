{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvnROOKjUN+fqyfnB4zU/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanghoshsbi/.github.io/blob/master/work/portfolio/pcaembeddings_graphical_correlation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4cDweLADhGY",
        "outputId": "fba36b27-a86b-487f-c052-cce34860f808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  96 of 96 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n",
            "2023-10-01 00:00:00\n",
            "2023-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering, AffinityPropagation, KMeans\n",
        "import yfinance as yf\n",
        "start_date = \"2023-10-01\"\n",
        "end_date = \"2023-12-31\"\n",
        "def get_nifty50_tickers():\n",
        "    #data = pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/STOCKS100.txt', sep='\\t')\n",
        "    data=pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/ind_nifty100list.csv')\n",
        "    nifty100 = data['Symbol'].apply(lambda x: x + \".NS\").tolist()\n",
        "    reject_lst=['MOTHERSUMI.NS', 'CADILAHC.NS', 'ADANITRANS.NS', 'SRTRANSFIN.NS', 'INFRATEL-EQ.NS','HDFC.NS','LTI.NS']\n",
        "    nifty_final= [item for item in nifty100 if item not in reject_lst]\n",
        "    return nifty_final\n",
        "def perform_clustering(stock_returns, method):\n",
        "    if method == \"agglomerative\":\n",
        "        # Agglomerative clustering with pre-determined number of clusters\n",
        "        clustering = AgglomerativeClustering(n_clusters=15, metric='euclidean', linkage='ward')\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"affinity_propagation\":\n",
        "        # Affinity propagation clustering\n",
        "        clustering = AffinityPropagation()\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"kmeans\":\n",
        "        # KMeans clustering (benchmark)\n",
        "        kmeans = KMeans(n_clusters=10)\n",
        "        clusters = kmeans.fit_predict(stock_returns)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid clustering method specified.\")\n",
        "    return clusters\n",
        "\n",
        "def construct_portfolio(clusters, embedding_data):\n",
        "    # Logic to select stocks based on clusters and distance in embedded space\n",
        "    portfolio = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        if len(cluster_indices) >= 10:\n",
        "            # Select top ten stocks with minimum Euclidean distance to cluster centers\n",
        "            distances = np.linalg.norm(embedding_data[cluster_indices] - np.mean(embedding_data[cluster_indices], axis=0), axis=1)\n",
        "            top_ten_indices = cluster_indices[np.argsort(distances)[:10]]\n",
        "            portfolio.extend(top_ten_indices)\n",
        "    return portfolio\n",
        "\n",
        "# ----- Main Loop -----\n",
        "stock_symbols=get_nifty50_tickers()\n",
        "data = yf.download(stock_symbols, start=start_date, end=end_date)[\"Adj Close\"]\n",
        "returns = data.pct_change().fillna(0)\n",
        "\n",
        "# Placeholder for handling quarterly updates\n",
        "for quarter in range(1, 5):\n",
        "    # Subset data by quarter (assuming quarterly data)\n",
        "    # ... Inside your main loop\n",
        "    for quarter in range(1, 5):\n",
        "      start_date = pd.to_datetime(f\"2023-Q{quarter}\")  # Dynamically define quarter start\n",
        "      end_date = start_date + pd.offsets.QuarterEnd()\n",
        "    print(start_date)\n",
        "    print(end_date)\n",
        "    quaterly_data = returns.loc[start_date:end_date]\n",
        "\n",
        "    # ... Now perform dimensionality reduction, clustering,\n",
        "    # and portfolio generation on 'quarterly_data'\n",
        "\n",
        "    # embedded_data = perform_dimensionality_reduction(data)\n",
        "    n_components = 2  # Reduce to 2 dimensions in this example\n",
        "    pca = PCA(n_components=n_components)\n",
        "    embedding_data = pca.fit_transform(quaterly_data)  # Obtain embeddings\n",
        "\n",
        "    # correlation_network = calculate_graphical_lasso(data)\n",
        "\n",
        "    clusters = perform_clustering(quaterly_data, method=\"agglomerative\")  # Or your chosen method\n",
        "    portfolio = construct_portfolio(clusters, embedding_data)\n",
        "\n",
        "    # Evaluate portfolio performance\n",
        "    # performance_metrics = evaluate_portfolio_performance(portfolio)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(portfolio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unTm5-sjFuUI",
        "outputId": "e0cee805-8163-48a9-8493-cd5706ef47e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em7DzMTJFvPq",
        "outputId": "c5adfcfd-2d93-412b-aa94-324e2be6c3d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[57, 29, 3, 55, 38, 17, 39, 30, 21, 5, 52, 0, 12, 8, 26, 32, 33, 34, 36, 15]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering, AffinityPropagation, KMeans\n",
        "import yfinance as yf\n",
        "\n",
        "start_date = \"2023-10-01\"\n",
        "end_date = \"2023-12-31\"\n",
        "\n",
        "def get_nifty50_tickers():\n",
        "    data = pd.read_csv('https://raw.githubusercontent.com/anirbanghoshsbi/data/main/ind_nifty100list.csv')\n",
        "    nifty100 = data['Symbol'].apply(lambda x: x + \".NS\").tolist()\n",
        "    reject_lst = ['MOTHERSUMI.NS', 'CADILAHC.NS', 'ADANITRANS.NS', 'SRTRANSFIN.NS',\n",
        "                    'INFRATEL-EQ.NS', 'HDFC.NS', 'LTI.NS']\n",
        "    return [item for item in nifty100 if item not in reject_lst]\n",
        "\n",
        "def perform_clustering(stock_returns, method):\n",
        "    if method == \"agglomerative\":\n",
        "        # Agglomerative with pre-determined clusters (Euclidean metric has no effect with Ward)\n",
        "        clustering = AgglomerativeClustering(n_clusters=15, linkage='ward')\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"affinity_propagation\":\n",
        "        clustering = AffinityPropagation()\n",
        "        clusters = clustering.fit_predict(stock_returns)\n",
        "    elif method == \"kmeans\":\n",
        "        kmeans = KMeans(n_clusters=10)\n",
        "        clusters = kmeans.fit_predict(stock_returns)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid clustering method specified.\")\n",
        "    return clusters\n",
        "\n",
        "def construct_portfolio(clusters, embedding_data):\n",
        "    portfolio = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        if len(cluster_indices) >= 10:\n",
        "            distances = np.linalg.norm(embedding_data[cluster_indices] - np.mean(embedding_data[cluster_indices], axis=0), axis=1)\n",
        "            top_ten_indices = cluster_indices[np.argsort(distances)[:10]]\n",
        "            portfolio.extend(top_ten_indices)\n",
        "    return portfolio\n",
        "\n",
        "# ----- Main Loop -----\n",
        "stock_symbols = get_nifty50_tickers()\n",
        "\n",
        "# Data download with basic error handling\n",
        "try:\n",
        "    data = yf.download(stock_symbols, start=start_date, end=end_date)[\"Adj Close\"]\n",
        "    returns = data.pct_change().fillna(0)\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading data: {e}\")\n",
        "    exit()  # Or handle it differently\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-J6_-MOJRPJ",
        "outputId": "d6e99d17-decd-464e-fd99-43ecef14bc63"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  96 of 96 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quarter handling (assumes focusing on 2023)\n",
        "for quarter in range(1, 5):\n",
        "    for quarter in range(1, 5):\n",
        "      start_date = pd.to_datetime(f\"2023-Q{quarter}\")  # Dynamically define quarter start\n",
        "      end_date = start_date + pd.offsets.QuarterEnd()\n",
        "\n",
        "\n",
        "    quarterly_data = returns.loc[start_date:end_date]\n",
        "    print(len(quarterly_data))\n",
        "    # Dimensionality Reduction\n",
        "    n_components = 2\n",
        "    pca = PCA(n_components=n_components)\n",
        "    embedding_data = pca.fit_transform(quarterly_data)\n",
        "\n",
        "    # Clustering\n",
        "    clusters = perform_clustering(quarterly_data, method=\"agglomerative\")\n",
        "    print('Deleted Previous Portfolio')\n",
        "    # Portfolio construction\n",
        "    portfolio = construct_portfolio(clusters, embedding_data)\n",
        "    print('Created Portfolio')\n",
        "\n",
        "    # Placeholder: Portfolio evaluation would go here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEjk3El5KV8y",
        "outputId": "12f66f3e-7049-4183-917d-2f395fb9e55e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n",
            "60\n",
            "Deleted Previous Portfolio\n",
            "Created Portfolio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[stock_symbols[i] for i in portfolio]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3NGFx-SG2q5",
        "outputId": "693dd712-67af-4b6c-93d1-79e7b974674b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JUBLFOOD.NS',\n",
              " 'DRREDDY.NS',\n",
              " 'ADANIPORTS.NS',\n",
              " 'JSWSTEEL.NS',\n",
              " 'HDFCLIFE.NS',\n",
              " 'BPCL.NS',\n",
              " 'HAVELLS.NS',\n",
              " 'EICHERMOT.NS',\n",
              " 'BRITANNIA.NS',\n",
              " 'APOLLOHOSP.NS',\n",
              " 'NAUKRI.NS',\n",
              " 'ACC.NS',\n",
              " 'BAJAJFINSV.NS',\n",
              " 'DMART.NS',\n",
              " 'DLF.NS',\n",
              " 'GLAND.NS',\n",
              " 'GODREJCP.NS',\n",
              " 'GRASIM.NS',\n",
              " 'HDFCAMC.NS',\n",
              " 'BANKBARODA.NS']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_portfolio_performance(portfolio, quarterly_data):\n",
        "    \"\"\"Calculates performance metrics for a portfolio against a benchmark.\n",
        "\n",
        "    Args:\n",
        "        portfolio (list): List of stock indices in the portfolio.\n",
        "        quarterly_data (pandas.DataFrame): Dataframe of stock returns for the quarter.\n",
        "        benchmark_data (pandas.Series): Returns of a benchmark index for the quarter.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of performance metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    portfolio_returns = quarterly_data.iloc[portfolio].mean(axis=1)  # Average across portfolio\n",
        "    #benchmark_returns = benchmark_data\n",
        "\n",
        "    performance_metrics = {}\n",
        "\n",
        "    # --- Example Metrics ---\n",
        "    # 1. Absolute Return\n",
        "    performance_metrics[\"portfolio_return\"] = portfolio_returns.sum() * 100\n",
        "    #performance_metrics[\"benchmark_return\"] = benchmark_returns.sum() * 100\n",
        "\n",
        "    # 2. Volatility (Standard Deviation)\n",
        "    performance_metrics[\"portfolio_std\"] = portfolio_returns.std() * np.sqrt(252) * 100  # Annualized\n",
        "    #performance_metrics[\"benchmark_std\"] = benchmark_returns.std() * np.sqrt(252) * 100\n",
        "\n",
        "    # 3. Sharpe Ratio\n",
        "    rf_rate = 0.05  # Placeholder: Assume a risk-free rate\n",
        "    performance_metrics[\"sharpe_ratio\"] = (portfolio_returns.mean() - rf_rate) / portfolio_returns.std()\n",
        "\n",
        "    # ... Calculate other metrics as needed ...\n",
        "\n",
        "    return performance_metrics\n"
      ],
      "metadata": {
        "id": "8liyWXK_KXKv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_portfolio_performance(portfolio, quarterly_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkLzBDb_MEc4",
        "outputId": "479cd96e-1161-4c9f-8395-41cea7db5c52"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'portfolio_return': 7.750777376852391,\n",
              " 'portfolio_std': 8.36196577607606,\n",
              " 'sharpe_ratio': -8.75638007505983}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JidfGHYcMHnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}